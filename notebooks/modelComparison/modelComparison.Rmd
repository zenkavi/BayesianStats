---
title: "Two methods for model comparison in Bayesian inference"
---

```{r}
library(gridExtra)
# library(cmdstanr)
library(rstan)
library(bridgesampling)
library(caret)
library(loo)
source('~/Dropbox/RangelLab/BayesianStats/helpers/k_fold.R')
```

# True model

`y = .5*x1 + noise` where `noise ~ N(0, .5)`

```{r}
set.seed(23423413)

make_fake_data = function(n=250, b1 = .5, sigma = .5){
  data = data.frame(x1 = rnorm(n, 0, 1),
                    x2 = rnorm(n, 0, 1))
  
  data = data %>% 
    mutate(noise = rnorm(n, mean = 0, sd = sigma),
           y = b1*x1+noise)
  return(data)
}

data = make_fake_data(n=2500)
```

# Frequentist comparison

```{r}
m1 = lm(y ~ x1, data)
m2 = lm(y ~ x1 + x2, data)
```

```{r}
summary(m1)
```

```{r}
summary(m2)
```

Adding `x2` to the model does not lead to a significant improvement (therefore simpler model with only `x1` would be chosen).

```{r}
anova(m1, m2)
```

Plotting `y` against both `x1` and `x2` as well as the predictions from the simpler and more complex models. Because there is no relationship between `x2` and `y` the plots for both model predictions look very similar to the relationship between `x1` and `y`.

```{r}
p1 = data %>% 
  ggplot(aes(x1, y)) +
  geom_point()

p2 = data %>% 
  ggplot(aes(x2, y)) +
  geom_point()

p3 = data %>%
  mutate(pred_m1 = predict(m1)) %>%
  ggplot(aes(pred_m1, y)) +
  geom_point()

p4 = data %>%
  mutate(pred_m2 = predict(m2)) %>%
  ggplot(aes(pred_m2, y)) +
  geom_point()

grid.arrange(p1, p2, p3, p4, ncol=2, nrow = 2)

```

```{r}
rm(p1, p2, p3, p4)
```

# Bayesian Model comparison (BMC)

Computing posterior model probabilities first for model with only `x1`

```{r}
m1_stan = stan_model("stanModels/modelComparison/fit_m1.stan")
m1_stanfit = sampling(m1_stan, data = list(N = nrow(data), y=data$y, x1 = data$x1),
                      show_messages=FALSE, verbose=FALSE, refresh= 0)
```

`b1` is the coefficient for `x1` and `sigma` is the sd of `noise`.

```{r}
m1_stanfit
```

```{r}
b_m1 <- bridge_sampler(m1_stanfit, silent = TRUE)
```

```{r}
m2_stan = stan_model("stanModels/modelComparison/fit_m2.stan")
m2_stanfit = sampling(m2_stan, data = list(N = nrow(data), y=data$y, x1 = data$x1, x2=data$x2),
                      show_messages=FALSE, verbose=FALSE, refresh= 0)
```

`b1` and `b2` are the coefficients for `x1`and `x2`, `sigma` is the sd of `noise`.

```{r}
m2_stanfit
```

```{r}
b_m2 <- bridge_sampler(m2_stanfit, silent = TRUE)
```

```{r}
post_prob(b_m1, b_m2)
```


# Posterior predictive checks (PPC)

LOO-CV and K-fold

```{r}
testIndices = createFolds(data$y, k = 5, list=TRUE, returnTrain = FALSE)
```

```{r}
m1_stan_cv = stan_model("stanModels/modelComparison/fit_m1_cv.stan")
```

```{r results="hide"}
m1_elpd = k_fold(m1_stan_cv, testIndices, simData = data, dataVarNames = c("x1", "y"), logLikVarName = "logLikelihood")
sum(m1_elpd)
```

```{r}
m2_stan_cv = stan_model("stanModels/modelComparison/fit_m2_cv.stan")
```

```{r results="hide"}
m2_elpd = k_fold(m2_stan_cv, testIndices, simData = data, dataVarNames = c("x1","x2", "y"), logLikVarName = "logLikelihood")
sum(m2_elpd)
```

Comparison of elpds using a frequentist perspective. Is the difference between the elpd's suggesting as 'strong' of a difference as the posterior model probabilities? 

Testing if the m1_elpd is lower than m2_elpd

```{r}
d = sum(m1_elpd) - sum(m2_elpd)
d_sd = sqrt(250)*sd(m1_elpd - m2_elpd)
1-pnorm(d/d_sd)
```

# Testing with more data

Try both methods on multiple datasets.

## BMC 

Iterate 100 times
Create fake data with 250 datapoints
Compute posterior model probabilities for both models for each iteration
Plot bar graph above but this time with standard errors across the iterations

```{r}
get_m_post_probs = function(data){
  
  if(!exists("m1_stan")){
    m1_stan = stan_model("stanModels/modelComparison/fit_m1.stan")
  }
  m1_stanfit = sampling(m1_stan, data = list(N = nrow(data), y=data$y, x1 = data$x1),
                      show_messages=FALSE, verbose=FALSE, refresh= 0) 
  b_m1 <- bridge_sampler(m1_stanfit, silent = TRUE)
  
  
  if(!exists("m2_stan")){
      m2_stan = stan_model("stanModels/modelComparison/fit_m2.stan")
  }
  m2_stanfit = sampling(m2_stan, data = list(N = nrow(data), y=data$y, x1 = data$x1, x2=data$x2),
                        show_messages=FALSE, verbose=FALSE, refresh= 0)
  b_m2 <- bridge_sampler(m2_stanfit, silent = TRUE)
  
  return(post_prob(b_m1, b_m2))
}
```

```{r}
out = data.frame()
n_int = 100
for(i in 1:n_int){
  data = make_fake_data()
  tmp = get_m_post_probs(data)
  tmp = t(as.data.frame(tmp))
  out = rbind(out, tmp)
  i = i+1
}
```

```{r}
out %>%
  gather(key, value) %>%
  ggplot(aes(key, value))+
  geom_boxplot()+
  xlab("")+
  ylab("p(m|y)")
```

## PPC

Iterate 100 times
Create fake data with 250 datapoints
Compute ELPDs for both models for each iteration
Compute p-value for each ELPD difference across iterations
Plot bar graph with ELPDs with standard errors across iterations

```{r}
get_elpds = function(data){
  testIndices = createFolds(data$y, k = 5, list=TRUE, returnTrain = FALSE)
  
  if(!exists("m1_stan_cv")){
      m1_stan_cv = stan_model("stanModels/modelComparison/fit_m1_cv.stan")
  }
  
  m1_elpd = k_fold(m1_stan_cv, testIndices, simData = data, dataVarNames = c("x1", "y"), logLikVarName = "logLikelihood")
  m1_elpd_sum = sum(m1_elpd)
  
  if(!exists("m2_stan_cv")){
    m2_stan_cv = stan_model("stanModels/modelComparison/fit_m2_cv.stan")
  }
  
  m2_elpd = k_fold(m2_stan_cv, testIndices, simData = data, dataVarNames = c("x1","x2", "y"), logLikVarName = "logLikelihood")
  m2_elpd_sum = sum(m2_elpd)
  
  d = sum(m1_elpd) - sum(m2_elpd)
  d_sd = sqrt(250)*sd(m1_elpd - m2_elpd)
  pval = 1-pnorm(d/d_sd)
  
  return(data.frame(m1_elpd_sum = m1_elpd_sum,
                    m2_elpd_sum = m2_elpd_sum,
                    pval = pval))
}
```

```{r eval=FALSE}
# out2 =   data.frame()
n_int = 100
# for(i in 1:n_int){
#   data = make_fake_data(n=2500)
#   tmp = get_elpds(data)
#   out2 = rbind(out2, tmp)
#   i = i+1
# }
```

```{r}
out2 %>%
  ggplot(aes(pval))+
  geom_histogram()+
  geom_vline(aes(xintercept = .05))
```

Proportion of samples that have significantly different ELPD's:

```{r}
out2 %>%
  mutate(sigdiff = ifelse(pval<.05, 1, 0)) %>%
  summarise(sigdiffprop = mean(sigdiff))
```