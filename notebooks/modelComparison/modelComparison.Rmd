---
title: "Two methods for model comparison in Bayesian inference"
---

```{r}
library(gridExtra)
# library(cmdstanr)
library(rstan)
library(bridgesampling)
library(caret)
library(loo)
```

# True model

```{r}
set.seed(23423413)

data = data.frame(x1 = rnorm(250, 0, 1),
                  x2 = rnorm(250, 0, 1))

data = data %>% 
  mutate(noise = rnorm(250, mean = 0, sd = .5),
         y = x1+noise)
```

# Frequentist comparison

```{r}
m1 = lm(y ~ x1, data)
m2 = lm(y ~ x1 + x2, data)
```

```{r}
summary(m1)
```

```{r}
summary(m2)
```

```{r}
anova(m1, m2)
```

```{r}
p1 = data %>% 
  ggplot(aes(x1, y)) +
  geom_point()

p2 = data %>% 
  ggplot(aes(x2, y)) +
  geom_point()

p3 = data %>%
  mutate(pred_m1 = predict(m1)) %>%
  ggplot(aes(pred_m1, y)) +
  geom_point()

p4 = data %>%
  mutate(pred_m2 = predict(m2)) %>%
  ggplot(aes(pred_m2, y)) +
  geom_point()

grid.arrange(p1, p2, p3, p4, ncol=2, nrow = 2)

```

```{r}
rm(p1, p2, p3, p4)
```

# Bayesian Model comparison (BMC)

Computing posterior model probabilities

```{r}
m1_stan = stan_model("../../stanModels/modelComparison/fit_m1.stan")
m1_stanfit = sampling(m1_stan, data = list(N = nrow(data), y=data$y, x1 = data$x1))
```

```{r}
m1_stanfit
```


```{r}
b_m1 <- bridge_sampler(m1_stanfit, silent = TRUE)
```

```{r}
m2_stan = stan_model("../../stanModels/modelComparison/fit_m2.stan")
m2_stanfit = sampling(m2_stan, data = list(N = nrow(data), y=data$y, x1 = data$x1, x2=data$x2))
```

```{r}
m2_stanfit
```

```{r}
b_m2 <- bridge_sampler(m2_stanfit, silent = TRUE)
```

```{r}
post_prob(b_m1, b_m2)
```

Note: there are no error bars! Those are just points.

```{r}
data.frame(log_p_y_m = c(b_m1$logml, b_m2$logml),
           model = c("true", "false")) %>%
  mutate(p_y_m = exp(log_p_y_m),
         denom = sum(p_y_m),
         p_m_y = p_y_m/denom,
         model = factor(model, levels = c("true", "false"))) %>%
  ggplot(aes(x=model, y=p_m_y))+
  geom_bar(stat="identity")+
  geom_point()+
  xlab("")+
  ylab("p(m|y)")
```


# Posterior predictive checks (PPC)

LOO-CV and K-fold

```{r}
testIndices = createFolds(data$y, k = 5, list=TRUE, returnTrain = FALSE)
```

```{r}
k_fold = function(aModel, testIndices, simData, dataVarNames, logLikVarName){
  
  numFolds = length(testIndices)
  
  #expected log pointwise predictive density
  elpd = 0
  
  for(i in 1:numFolds){
    cur_ind = testIndices[[i]]
    
    m_data = list(N_train = nrow(simData) - length(cur_ind), N_test = length(cur_ind))
    
    for (j in 1:length(dataVarNames)){
      m_data[[paste0(dataVarNames[j], '_train')]] = simData[-cur_ind, dataVarNames[j]]
      m_data[[paste0(dataVarNames[j], '_test')]] = simData[cur_ind, dataVarNames[j]]
    }
    
    fit = sampling(aModel, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
    
    fold_llpd = extract_log_lik(fit, logLikVarName) #requires loo
    
    fold_llpd_means = colMeans(fold_llpd) #mean loglik for each left out train datapoint across samples
    #fold_elpd_increment = sum(fold_llpd_means) #sum of mean logliks of each train datapoint
    #elpd = elpd+fold_elpd_increment 
    elpd = c(elpd, fold_llpd_means)
  }
  
  return(elpd)
}
```

```{r}
m1_stan_cv = stan_model("../../stanModels/modelComparison/fit_m1_cv.stan")
```

```{r results="hide"}
m1_elpd = k_fold(m1_stan_cv, testIndices, simData = data, dataVarNames = c("x1", "y"), logLikVarName = "logLikelihood")
sum(m1_elpd)
```

```{r}
m2_stan_cv = stan_model("../../stanModels/modelComparison/fit_m2_cv.stan")
```

```{r results="hide"}
m2_elpd = k_fold(m2_stan_cv, testIndices, simData = data, dataVarNames = c("x1","x2", "y"), logLikVarName = "logLikelihood")
sum(m2_elpd)
```

Comparison of elpds:

```{r}
d = sum(m1_elpd) - sum(m2_elpd)
d_sd = sqrt(250)*sd(m1_elpd - m2_elpd)
1-pnorm(d/d_sd)
```

# More data

Try both methods on multiple datasets.

## BMC 

## PPC