---
title: "Stan model_0: Basics"
---

```{r}
library(rstan)
```

```{r}
rstan_options(auto_write = TRUE)
```

# Model_0: Basic model with predicted data

Create fake data

```{r}
Y = rnorm(10, 1.5, .2)
```

Compile and run the MCMC

```{r}
fit = stan('stanModels/LambertTextbookExamples/model_0.stan', iter=200, chains=4,
           data = list(Y=Y))
```

Interpreting results (with added `generated quantities` block)

```{r}
print(fit, probs=c(.25, .5, .75))
```

Extract and plot posterior

```{r}
data.frame(mu =extract(fit, 'mu')[[1]]) %>%
  ggplot(aes(x=mu))+
  geom_histogram()
```

Interactive exploration in `shinystan`

```{r}
# require(shinystan)
```


```{r}
# aFit = as.shinystan(fit)
# launch_shinystan(aFit)
```

# Model_0.1: Covariate model

New model where height  `Y` is a function of weight `X`

```{r}
N = 100
X = rnorm(N, 60, 10)
beta = .3
sigma = .3
Y = beta * log(X) + rnorm(N, 0, sigma)
fit = stan('stanModels/model_0.1.stan', iter = 200, chains = 4,
           data = list(Y=Y, X=X, N=N))
```

```{r}
print(fit, probs=c(.25,.5,.75))
```

# Model_0.2: Transformed parameters

Fit new model with `transformed parameters` block

```{r}
Y = rnorm(10, 1.5, .2)
fit = stan('stanModels/model_0.2.stan', iter = 200, chains = 4, data= list(Y=Y))
```

```{r}
print(fit, probs=c(.25,.5,.75))
```

# Model_0.3: Avoiding memory overload

Creating posterior predictive check variable within `{}` to avoid memory overhead.

```{r}
Y = rnorm(10, 1.5, .2)
fit = stan('stanModels/model_0.3.stan', iter = 200, chains = 4, data= list(Y=Y))
```

Note lack of `lSimData` variable in the output

```{r}
print(fit, probs=c(.25,.5,.75))
```

# Model_0.4: Custom distributions

Creating custom probability distributions.

```{r}
N = 4
X = c(-1.5, 2.3, 0.1, -0.4)
fit = stan('stanModels/model_0.4.stan', iter = 200, chains = 4, data= list(N=N, X=X))
```

```{r}
print(fit, probs=c(.25,.5,.75))
```

# Model_0.5 and Model_0.6: WAIC and LOO-CV

Using WAIC and LOO-CV

Generate data from a t-distribution and compare two models that describe a true and false data generating processes.

```{r}
N = 10000
X = rt(N, 5)
```

```{r}
require(loo)
```

Compare models using `WAIC`

```{r}
fit1 = stan('stanModels/model_0.5.stan', iter=200, chains=4, data=list(N=N, X=X))
logLikelihood1 = extract_log_lik(fit1, 'logLikelihood')
WAIC1 = waic(logLikelihood1)
```
```{r}
WAIC1
```

```{r}
fit2 = stan('stanModels/model_0.6.stan', iter=200, chains=4, data=list(N=N, X=X))
logLikelihood2 = extract_log_lik(fit2, 'logLikelihood')
WAIC2 = waic(logLikelihood2)
```

```{r}
WAIC2
```
Difference in `elpd` is much greater than the standard error; i.e. there is a significant difference in performance between the two models.

```{r}
loo_compare(WAIC1, WAIC2)
```

Compare models using `LOO-CV`

```{r}
LOO1 = loo(logLikelihood1)
LOO1
```

```{r}
LOO2 = loo(logLikelihood2)
LOO2
```

```{r}
loo_compare(LOO1, LOO2)
```

# Model_0.7 and Model_0.8: Explicit CV

Explicit cross validation

```{r}
require(caret)
```

```{r}
testIndices = createFolds(X, k=5, list=T, returnTrain=F)
```

```{r}
kFold = function(aModel, testIndices, X){
  numFolds = length(testIndices)
  
  lPointLogLikelihoodTotal = vector()
  
  for(i in 1:numFolds){
    XTest = X[testIndices[[i]]]
    XTrain = X[-testIndices[[i]]]
    fit = sampling(aModel, iter=200, chains=4, data=list(NTest=2000, NTrain=8000, XTrain=XTrain, XTest=XTest))
    logLikelihood1 = extract_log_lik(fit, 'logLikelihood')
    lPointLogLikelihood1 = colMeans(logLikelihood1)
    lPointLogLikelihoodTotal = c(lPointLogLikelihoodTotal, lPointLogLikelihood1)
  }
  
  #return(lPointLogLikelihoodTotal)
  return(list(lPointLogLikelihoodTotal=lPointLogLikelihoodTotal, last_fit=fit))
}
```

```{r}
Model1 = stan_model('stanModels/LambertTextbookExamples/model_0.7.stan')
Model2 = stan_model('stanModels/LambertTextbookExamples/model_0.8.stan')
```

```{r}
out = kFold(Model1, testIndices, X)
```

```{r}
str(extract_log_lik(out$last_fit, 'logLikelihood'))
```

```{r}
str(colMeans(extract_log_lik(out$last_fit, 'logLikelihood')))
```

```{r}
str(out$lPointLogLikelihoodTotal)
```


```{r}
lELPD1 = kFold(Model1, testIndices, X)
lELPD2 = kFold(Model2, testIndices, X)
```

```{r}
sum(lELPD1$lPointLogLikelihoodTotal)
```

```{r}
sum(lELPD2$lPointLogLikelihoodTotal)
```

# Model_0.9: Transformed parameters

Transformed parameters and Jacobians

Example model where the defined parameter `alpha` does not have prior defined in the `model` but instead we specify a parameter for the transformed parameter `theta`. This will give a warning and an incorrect estimate for `theta` because nonilnear transformations on parameters that are then used for sampling require the definition of a Jacobian (i.e. the description of how the nonlinear transform changes the probability density of the transformed parameter compared to the original)

```{r}
N=4
Y=c(0,0,1,0)
fit = stan('stanModels/model_0.9.stan', iter=200, chains=4, data=list(N=N, Y=Y))
```

```{r}
print(fit, probs=c(.25,.5,.75))
```

# Model_0.10: Jacobians

Corrected model where the log probability is correctly updated using the Jacobian

```{r}
fit = stan('stanModels/model_0.10.stan', iter=200, chains=4, data=list(N=N, Y=Y))
```

```{r}
print(fit, probs=c(.25,.5,.75))
```

# Model_0.11: Discrete variables

Estimating coin identity and head probability of two biased coins in 20 experiments with 10 coin flips each.  

Generate fake data

```{r}
nStudy = 20
N = 10
Z = matrix(nrow=N, ncol=nStudy)
theta = c(.1, .9)
state = vector(length = nStudy)
for (i in 1:nStudy){
  if (runif(1)<.5){
    Z[,i] = rbinom(N, 1, theta[1])
    state[i] = 1
  } else{
    Z[,i] = rbinom(N, 1, theta[2])
    state[i] = 0
  }
}

X = colSums(Z)
```

```{r}
state
```

```{r}
fit = stan('stanModels/model_0.11.stan', iter=200, chains=4, data=list(X=X, N=N, nStudy=nStudy))
```

```{r}
print(fit, probs = c(.25,.5,.75), c('theta', 'pstate'))
```


