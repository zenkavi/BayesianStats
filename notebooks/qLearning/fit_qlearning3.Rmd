---
title: "RL simulation and parameter recovery with Stan III: Model comparison"
---

**Even if we can't do a good job with estimating the exact parameters for subjects can we distinguish between (cognitive) models and reliably identify the correct data generating process?**

```{r}
source('/Users/zeynepenkavi/Dropbox/RangelLab/BayesianStats/helpers/demo_QlearningSimulation.R')
library(loo)
library(caret)
library(bridgesampling)
```

```{r}
sim_data = demo_QlearningSimulation(alpha = .65, beta = 2.5)
```

True learning rate `alpha`

```{r}
true_alpha = VBA_sigmoid(sim_data$simulation$evolution, inverse=FALSE)
true_alpha
```

True inverse temperature `beta`

```{r}
true_beta = exp(sim_data$simulation$observation)
true_beta
```

## Predictive accuracy with CV

Using `caret` to make 5 folds for cross validation.

```{r}
testIndices = createFolds(sim_data$choices, k = 5, list=TRUE, returnTrain = FALSE)
```

```{r}
## Adapted from Lambert textbook p. 397
k_fold = function(aModel, testIndices, simData){
  numFolds = length(testIndices)
  
  #expected log pointwise predictive density
  elpd = 0
  
  for(i in 1:numFolds){
    cur_ind = testIndices[[i]]
  
    T_train = length(sim_data$choices) - length(cur_ind)
    T_test = length(cur_ind)
  
    choice_train = simData$choices[-cur_ind] #adding 1 bc categorical_logit has support over [1,2]
    choice_test = simData$choices[cur_ind]
    
    outcome_train = simData$feedback[-cur_ind] 
    outcome_test = simData$feedback[cur_ind] 
    
    m_data = list(T_train = T_train, T_test = T_test, 
                  choice_train = choice_train, choice_test = choice_test, 
                  outcome_train = outcome_train, outcome_test = outcome_test)
    
    fit = sampling(aModel, iter=1000, chains=4, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
    
    fold_llpd = extract_log_lik(fit, 'log_lik') #log likelihood for each sample (1000) and observations in this fold
    
    #Based on https://discourse.mc-stan.org/t/calculating-elpd-values-for-a-stan-model-k-fold-cross-validation/3570/7
    #fold_llpd = exp(fold_llpd) #exponentiate each element
    fold_llpd_means = colMeans(fold_llpd) # mean likelihood across samples for each y_test in this fold
    #fold_llpd_means = log(fold_llpd_means)
    fold_elpd_increment = sum(fold_llpd_means)
    elpd = c(elpd, fold_elpd_increment)
    
    #For a standard error you need standard error of a sum i.e. sd*sqrt(n)
  }
  
  return(list(elpd_sum = sum(elpd), elpd_se = sd(elpd)*sqrt(length(elpd))))
}
```

Use `stan` to get parameters that generated simulated data.

```{r}
m_true = stan_model('../stanModels/qLearning/QLearning_cv_trueModel.stan')
```

```{r}
m_twoAlphas = stan_model('../stanModels/qLearning/QLearning_cv_twoAlphas.stan')
m_diffAlphas = stan_model('../stanModels/qLearning/QLearning_cv_diffAlphas.stan')
m_strawMan = stan_model('../stanModels/qLearning/QLearning_cv_strawMan.stan')
```

```{r results="hide"}
ELPD_true = k_fold(m_true, testIndices, sim_data)
```

```{r results="hide"}
ELPD_twoAlphas = k_fold(m_twoAlphas, testIndices, sim_data)
```

```{r results="hide"}
ELPD_diffAlphas = k_fold(m_diffAlphas, testIndices, sim_data)
```

```{r results="hide"}
ELPD_strawMan = k_fold(m_strawMan, testIndices, sim_data)
```

```{r}
data.frame(ELPD_strawMan) %>%
  mutate(model = "straw man") %>%
  rbind(data.frame(ELPD_diffAlphas) %>%
  mutate(model = "diff Alphas")) %>%
  rbind(data.frame(ELPD_twoAlphas) %>%
  mutate(model = "two Alphas")) %>%
  rbind(data.frame(ELPD_true) %>%
  mutate(model = "true")) %>%
  mutate(model = factor(model, levels = c("true", "two Alphas", "diff Alphas", "straw man"), labels = c("true", "two Alphas", "diff Alphas", "play all"))) %>%
  ggplot(aes(model))+
  geom_point(aes(y=elpd_sum), size=4)+
  geom_errorbar(aes(ymin = elpd_sum-elpd_se, ymax = elpd_sum+elpd_se, width=0))+
  xlab("")+
  ylab("ELPD")
```

## Full Bayesian model comparison

Bridge sampling to calculate marginal likelihood and compute $p(m|y)$ for each model. Based on this [vignette](https://cran.r-project.org/web/packages/bridgesampling/vignettes/bridgesampling_example_stan.html).

```{r}
m_true = stan_model('../stanModels/qLearning/QLearning_full_trueModel.stan')
m_twoAlphas = stan_model('../stanModels/qLearning/QLearning_full_twoAlphas.stan')
m_diffAlphas = stan_model('../stanModels/qLearning/QLearning_full_diffAlphas.stan')
m_strawMan = stan_model('../stanModels/qLearning/QLearning_full_strawMan.stan')
```

```{r}
T_train = length(sim_data$choices)

choice_train = sim_data$choices

outcome_train = sim_data$feedback

m_data = list(T_train = T_train, 
              choice_train = choice_train, 
              outcome_train = outcome_train)
```

```{r}
f_true = sampling(m_true, iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
f_twoAlphas = sampling(m_twoAlphas, iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
f_diffAlphas = sampling(m_diffAlphas,iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
f_strawMan = sampling(m_strawMan, iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
b_true <- bridge_sampler(f_true, silent = TRUE)
```

```{r}
b_twoAlphas <- bridge_sampler(f_twoAlphas, silent = TRUE)
```

```{r}
b_diffAlphas <- bridge_sampler(f_diffAlphas, silent = TRUE)
```

```{r}
b_strawMan <- bridge_sampler(f_strawMan, silent = TRUE)
```

```{r}
post_prob(b_true, b_twoAlphas, b_diffAlphas, b_strawMan)
```

```{r}
data.frame(log_p_y_m = c(b_true$logml, b_twoAlphas$logml, b_diffAlphas$logml, b_strawMan$logml),
           model = c("true", "two Alphas", "diff Alphas", "play all")) %>%
  mutate(p_y_m = exp(log_p_y_m),
         denom = sum(p_y_m),
         p_m_y = p_y_m/denom,
         model = factor(model, levels = c("true", "two Alphas", "diff Alphas", "play all"))) %>%
  ggplot(aes(x=model, y=p_m_y))+
  geom_bar(stat="identity")+
  geom_point()+
  xlab("")+
  ylab("p(m|y)")
```