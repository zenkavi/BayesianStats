---
title: "RL simulation and parameter recovery with Stan III: Model comparison"
---

**Even if we can't do a good job with estimating the exact parameters for subjects can we distinguish between (cognitive) models and reliably identify the correct data generating process?**

```{r}
source('/Users/zeynepenkavi/Dropbox/RangelLab/BayesianStats/helpers/demo_QlearningSimulation.R')
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(loo)
library(caret)
library(bridgesampling)
```

Simulate data with two learning rates (learning 3 times faster from negative RPEs than from positive RPEs)

```{r}
sim_data = demo_QlearningSimulation(alpha = c(.25, .75), beta = 2.5, f_fname = 'f_Qlearning_twoAlphas')
```

True learning rates `alpha_pos` and `alpha_neg`

```{r}
raw_alpha = sim_data$simulation$evolution
true_alpha = c()
for(i in 1:length(raw_alpha)){
  true_alpha[i] = VBA_sigmoid(raw_alpha[i], inverse=FALSE)
}
true_alpha
```

True inverse temperature `beta`

```{r}
true_beta = exp(sim_data$simulation$observation)
true_beta
```

## Predictive accuracy with CV

Using `caret` to make 5 folds for cross validation.

```{r}
testIndices = createFolds(sim_data$choices, k = 5, list=TRUE, returnTrain = FALSE)
data = data.frame(choice = sim_data$choices, outcome = sim_data$feedback)
```

```{r results="hide"}
m_oneAlpha = stan_model('stanModels/qLearning/QLearning_cv_oneAlpha.stan')
ELPD_oneAlpha  = k_fold(m_oneAlpha, testIndices, simData = data, dataVarNames = c("choice", "outcome"), logLikVarName = "log_lik")

sum(ELPD_oneAlpha)
```

```{r results="hide"}
m_twoAlphas = stan_model('stanModels/qLearning/QLearning_cv_twoAlphas.stan')
ELPD_twoAlphas  = k_fold(m_twoAlphas, testIndices, simData = data, dataVarNames = c("choice", "outcome"), logLikVarName = "log_lik")
sum(ELPD_twoAlphas)
```

```{r results="hide"}
m_diffAlphas = stan_model('stanModels/qLearning/QLearning_cv_diffAlphas.stan')
ELPD_diffAlphas = k_fold(m_diffAlphas, testIndices, simData = data, dataVarNames = c("choice", "outcome"), logLikVarName = "log_lik")
sum(ELPD_diffAlphas)
```

```{r results="hide"}
m_strawMan = stan_model('stanModels/qLearning/QLearning_cv_strawMan.stan')
ELPD_strawMan = k_fold(m_strawMan, testIndices, simData = data, dataVarNames = c("choice", "outcome"), logLikVarName = "log_lik")
```

```{r}
data.frame(ELPD_strawMan) %>%
  mutate(model = "straw man") %>%
  rbind(data.frame(ELPD_diffAlphas) %>%
  mutate(model = "diff Alphas")) %>%
  rbind(data.frame(ELPD_twoAlphas) %>%
  mutate(model = "two Alphas")) %>%
  rbind(data.frame(ELPD_oneAlpha) %>%
  mutate(model = "true")) %>%
  mutate(model = factor(model, levels = c("oneAlpha", "two Alphas", "diff Alphas", "straw man"), labels = c("one Alpha", "two Alphas", "diff Alphas", "play all"))) %>%
  ggplot(aes(model))+
  geom_point(aes(y=elpd_sum), size=4)+
  geom_errorbar(aes(ymin = elpd_sum-elpd_se, ymax = elpd_sum+elpd_se, width=0))+
  xlab("")+
  ylab("ELPD")
```

## Full Bayesian model comparison

Bridge sampling to calculate marginal likelihood and compute $p(m|y)$ for each model. Based on this [vignette](https://cran.r-project.org/web/packages/bridgesampling/vignettes/bridgesampling_example_stan.html).

```{r}
m_true = stan_model('stanModels/qLearning/QLearning_full_oneAlpha.stan')
m_twoAlphas = stan_model('stanModels/qLearning/QLearning_full_twoAlphas.stan')
m_diffAlphas = stan_model('stanModels/qLearning/QLearning_full_diffAlphas.stan')
m_strawMan = stan_model('stanModels/qLearning/QLearning_full_strawMan.stan')
```

```{r}
T_train = length(sim_data$choices)

choice_train = sim_data$choices

outcome_train = sim_data$feedback

m_data = list(T_train = T_train, 
              choice_train = choice_train, 
              outcome_train = outcome_train)
```

```{r}
f_oneAlpha = sampling(m_true, iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
f_twoAlphas = sampling(m_twoAlphas, iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
f_diffAlphas = sampling(m_diffAlphas,iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
f_strawMan = sampling(m_strawMan, iter = 50000, warmup = 1000, chains = 3, data=m_data, show_messages=FALSE, verbose=FALSE, refresh= 0)
```

```{r}
b_oneAlpha <- bridge_sampler(f_true, silent = TRUE)
```

```{r}
b_twoAlphas <- bridge_sampler(f_twoAlphas, silent = TRUE)
```

```{r}
b_diffAlphas <- bridge_sampler(f_diffAlphas, silent = TRUE)
```

```{r}
b_strawMan <- bridge_sampler(f_strawMan, silent = TRUE)
```

```{r}
post_prob(b_true, b_twoAlphas, b_diffAlphas, b_strawMan)
```

```{r}
data.frame(log_p_y_m = c(b_oneAlpha$logml, b_twoAlphas$logml, b_diffAlphas$logml, b_strawMan$logml),
           model = c("one Alpha", "two Alphas", "diff Alphas", "play all")) %>%
  mutate(p_y_m = exp(log_p_y_m),
         denom = sum(p_y_m),
         p_m_y = p_y_m/denom,
         model = factor(model, levels = c("one Alpha", "two Alphas", "diff Alphas", "play all"))) %>%
  ggplot(aes(x=model, y=p_m_y))+
  geom_bar(stat="identity")+
  geom_point()+
  xlab("")+
  ylab("p(m|y)")
```