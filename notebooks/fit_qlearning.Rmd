---
title: "RL simulation and parameter recovery with Stan"
---

## Data

Translating Deanizeau et al. (2014) Q-learning example

```{r}
source('/Users/zeynepenkavi/Dropbox/RangelLab/BayesianStats/helpers/demo_QlearningSimulation.R')
```

Generate simulated data

```{r}
sim_data = demo_QlearningSimulation()
```

True learning rate

```{r}
sim_data$simulation$evolution
```

True inverse temperature

```{r}
sim_data$simulation$observation
```

Figure 1: Simulated Q-learning behavior (from [demo_Qlearning.m](https://github.com/MBB-team/VBA-toolbox/blob/master/demos/3_behavioural/demo_Qlearning.m))

```{r}
df = data.frame(choices = c(sim_data$y), 
                tendency = c(sim_data$y - sim_data$e))
```

```{r}
df %>%
  mutate(trial_n = 1:n()) %>%
  ggplot(aes(x=trial_n))+
  geom_jitter(aes(y=choices, color="choices"), width=.01, height=.01)+
  geom_line(aes(y=tendency, color="p(y=1|theta,phi,m): behavioural tendency"))+
  scale_colour_manual(name="",values=c("choices" = "black", "p(y=1|theta,phi,m): behavioural tendency" = "red"))+
  theme(legend.position = "bottom")
```

## Parameter estimation

Now that you have the data invert it using Stan to get parameters.

```{r}
TN = length(sim_data$choice)
choice = sim_data$choices #adding 1 bc categorical_logit has support over [1,2]
outcome = sim_data$feedback
m_data = list(T = TN, choice = choice, outcome = outcome)
```

```{r}
m = stan_model('../stanModels/QLearning_binom.stan')
```

```{r}
fit_nuts = sampling(m, iter=1000, chains=4, data=m_data)
```

```{r}
fit_vb = vb(m, data=m_data)
```

### Comparison of posteriors

Both inversion methods overestimate both parameters. This is due to the dependency between them that will be clearer in the pair plots below. The independence assumption in ADVI does not seem to be able to improve this.

```{r}
data.frame(extract(fit_nuts, c("alpha", "beta"))) %>%
  mutate(alg = "NUTS") %>%
  gather(key, value, -alg) %>%
  group_by(key) %>%
  mutate(med_est = median(value),
         true_val = ifelse(key == "alpha", sim_data$simulation$evolution, sim_data$simulation$observation)) %>%
  
  rbind(data.frame(extract(fit_vb, c("alpha", "beta"))) %>%
          mutate(alg = "ADVI") %>%
          gather(key, value, -alg) %>%
          group_by(key) %>%
          mutate(med_est = median(value),
                 true_val = ifelse(key == "alpha", sim_data$simulation$evolution, sim_data$simulation$observation))) %>%
  gather(est_type, estimate, -alg, -key, -value) %>%
  
  ggplot(aes(x = value, fill=alg))+
  geom_histogram(position="identity", alpha = .5)+
  facet_grid(alg~key, scales='free')+
  geom_vline(aes(xintercept=estimate, linetype = est_type)) +
  scale_linetype_manual(name="", values=c("med_est" = "solid", "true_val" = "dashed"))+
  scale_fill_manual(name="", values=c("NUTS" = "purple", "ADVI" = "dark green"))+
  theme(legend.position="bottom")+
  xlab("")+
  ylab("")
```


```{r}
summary(fit_nuts, pars = c('alpha', 'beta', 'log_lik'))$summary
```

According to [Yao et al. (2018)](http://www.stat.columbia.edu/~gelman/research/published/Evaluating_Variational_Inference.pdf) `khat` "provide[s] the desired diagnostic measurement between the true posterior 
and the VI approximation"

```{r}
summary(fit_vb, pars = c('alpha', 'beta', 'log_lik'))$summary
```

### Pair plots colored by log likelihood

```{r}
data.frame(extract(fit_nuts, c('alpha', 'beta', 'log_lik'))) %>%
  mutate(alg = "NUTS") %>%
  rbind(data.frame(extract(fit_vb, c('alpha', 'beta', 'log_lik'))) %>%
  mutate(alg = "ADVI"))%>%
  ggplot(aes(x=A, y=tau, color=log_lik))+
  geom_point() +
  facet_grid(~alg)+
  theme(legend.position = "bottom")+
  ylab("Inverse temperature")+
  xlab("Learning rate")
```
